{
  "hash": "437487a3fd126469dc550485cbe75603",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Data Analysis\"\nsubtitle: \"Methodenfortbildung der ASP\"\ndescription: \"Correlation | Regression | t-Tests | ANOVA\"\nauthor: \"**Maik Bieleke, PhD**\"\ninstitute: \"University of Konstanz\"\ndate: 11/16/2024\ndate-format: long\nformat: \n  revealjs:\n    transition: slide\n    fontsize: 20pt\n    chalkboard: true\n    slide-number: true\n    theme: [simple, _styles/unikn.scss]\n    footer: \"[https://maikbieleke.com/workshops/startr-2024-asp/](https://maikbieleke.com/workshops/startr-2024-asp/)\"\n    margin: 0.25\n    highlight-style: a11y\nfrom: markdown+emoji\nrevealjs-plugins:\n  - attribution\n---\n\n::: {.cell}\n\n:::\n\n\n# Correlation\n\n## The *correlation* package\n\n::: columns\n::: {.column width=\"60%\"}\nThe *correlation* package is an [easystats package](https://easystats.github.io/easystats/) focused on correlation analysis.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# install.packages(\"correlation\")\nlibrary(correlation)\n```\n:::\n\n:::\n\n::: {.column width=\"40%\"}\n![](figures/08-analysis/correlation-hex.png){fig-align=\"center\"}\n:::\n:::\n\n::: footer\n<https://easystats.github.io/easystats/>\n:::\n\n## Computing single correlations\n\nA single correlation can be determined with the `cor_test()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Correlation between players' value and overall attribute\ncor_test(pes, \"approach_effort\", \"avoid_effort\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nParameter1      |   Parameter2 |     r |         95% CI | t(287) |         p\n----------------------------------------------------------------------------\napproach_effort | avoid_effort | -0.79 | [-0.83, -0.74] | -21.97 | < .001***\n\nObservations: 289\n```\n\n\n:::\n:::\n\n\n\n\n## Plotting single correlations\n\nWe can plot the correlation using the `plot()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nr <- cor_test(pes, \"approach_effort\", \"avoid_effort\")\nplot(r)\n```\n\n::: {.cell-output-display}\n![](startr-08_statistics_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n\n\n\n## Computing multiple correlations\n\nWe can compute correlations between sets of variables with the `correlation()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Select variables of interest\nvariables_pes <- select(pes, approach_effort, avoid_effort)\nvariables_ipaq <- select(pes, ipaq_sitt, ipaq_walk, ipaq_mopa, ipaq_vipa, ipaq_mvpa)\n\n# Compute correlations\ncorrelation(data = variables_pes, data2 = variables_ipaq)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Correlation Matrix (pearson-method)\n\nParameter1      | Parameter2 |        r |         95% CI |   t(287) |         p\n-------------------------------------------------------------------------------\napproach_effort |  ipaq_sitt |    -0.28 | [-0.38, -0.17] |    -4.96 | < .001***\napproach_effort |  ipaq_walk | 1.74e-04 | [-0.12,  0.12] | 2.95e-03 | > .999   \napproach_effort |  ipaq_mopa |     0.18 | [ 0.06,  0.29] |     3.04 | 0.010*   \napproach_effort |  ipaq_vipa |     0.31 | [ 0.20,  0.41] |     5.49 | < .001***\napproach_effort |  ipaq_mvpa |     0.28 | [ 0.17,  0.38] |     4.88 | < .001***\navoid_effort    |  ipaq_sitt |     0.27 | [ 0.16,  0.37] |     4.74 | < .001***\navoid_effort    |  ipaq_walk | 1.85e-03 | [-0.11,  0.12] |     0.03 | > .999   \navoid_effort    |  ipaq_mopa |    -0.16 | [-0.27, -0.05] |    -2.79 | 0.017*   \navoid_effort    |  ipaq_vipa |    -0.28 | [-0.38, -0.17] |    -4.90 | < .001***\navoid_effort    |  ipaq_mvpa |    -0.25 | [-0.36, -0.14] |    -4.39 | < .001***\n\np-value adjustment method: Holm (1979)\nObservations: 289\n```\n\n\n:::\n:::\n\n\n\n\n## Correlation matrix\n\nWe can use the `summary()`function to get a correlation matrix.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Take all variables together\nvariables <- select(pes, approach_effort, avoid_effort, \n                    ipaq_sitt, ipaq_walk, ipaq_mopa, ipaq_vipa, ipaq_mvpa)\n\n# Compute and save correlations\nr <- correlation(variables)\n\n# Generate correlation matrix\nsummary(r)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Correlation Matrix (pearson-method)\n\nParameter       | ipaq_mvpa | ipaq_vipa | ipaq_mopa | ipaq_walk | ipaq_sitt | avoid_effort\n------------------------------------------------------------------------------------------\napproach_effort |   0.28*** |   0.31*** |     0.18* |  1.74e-04 |  -0.28*** |     -0.79***\navoid_effort    |  -0.25*** |  -0.28*** |    -0.16* |  1.85e-03 |   0.27*** |             \nipaq_sitt       | -8.59e-03 |     -0.03 |      0.02 |   0.29*** |           |             \nipaq_walk       |   0.26*** |     0.17* |   0.31*** |           |           |             \nipaq_mopa       |   0.88*** |   0.60*** |           |           |           |             \nipaq_vipa       |   0.91*** |           |           |           |           |             \n\np-value adjustment method: Holm (1979)\n```\n\n\n:::\n:::\n\n\n\n\n## Correlation plot\n\nWe can use the `plot()`function to plot the correlation matrix.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compute and save correlations and correlation matrix\nr <- correlation(variables)\nrmat <- summary(r)\n\n# Generate correlation plot\nplot(rmat)\n```\n\n::: {.cell-output-display}\n![](startr-08_statistics_files/figure-revealjs/unnamed-chunk-7-1.png){width=960}\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n# Regression\n\n## Overview\n\nThere are numerous regression models available in R. We will focus on the Base R implementation of the linear regression model.\n\n::: columns\n::: {.column width=\"70%\"}\nThere are three aspects of regression:\n\n-   **model estimation**: `lm()` function in base R\n-   **parameter evaluation**: *parameters* package\n-   **model performance**: *performance* package\n:::\n\n::: {.column width=\"30%\"}\n![](figures/08-analysis/parameters-hex.png) ![](figures/08-analysis/performance-hex.png)\n:::\n:::\n\nThe *parameters* and the *performance* package are part of the [easystats](https://easystats.github.io/easystats/) package collection.\n\n::: footer\n<https://easystats.github.io/easystats/>\n:::\n\n## Simple regression\n\nWe can use the `lm()` function to estimate a simple linear regression model. The `summary()` function provides the standard output.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# estimate regression model with a single predictor: dv ~ iv\nmodel <- lm(ipaq_mvpa ~ approach_effort, data = pes)\n\n# get the standard output\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = ipaq_mvpa ~ approach_effort, data = pes)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-485.63 -242.97 -119.10   93.56 2867.03 \n\nCoefficients:\n                Estimate Std. Error t value Pr(>|t|)    \n(Intercept)      -148.47     110.85  -1.339    0.181    \napproach_effort   146.13      29.95   4.879 1.77e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 443.2 on 287 degrees of freedom\nMultiple R-squared:  0.07658,\tAdjusted R-squared:  0.07336 \nF-statistic:  23.8 on 1 and 287 DF,  p-value: 1.774e-06\n```\n\n\n:::\n:::\n\n\n## Model parameters and performance\n\nWe can use the `parameters()` and `performance()` to extract parameters and performance metrics.\n\n- Parameters\n\n\n  ::: {.cell}\n  \n  ```{.r .cell-code}\n  # parameters\n  parameters::parameters(model)\n  ```\n  \n  ::: {.cell-output .cell-output-stdout}\n  \n  ```\n  Parameter       | Coefficient |     SE |            95% CI | t(287) |      p\n  ----------------------------------------------------------------------------\n  (Intercept)     |     -148.47 | 110.85 | [-366.65,  69.70] |  -1.34 | 0.181 \n  approach effort |      146.13 |  29.95 | [  87.17, 205.08] |   4.88 | < .001\n  ```\n  \n  \n  :::\n  :::\n\n\n- Standardized parameters\n\n\n  ::: {.cell}\n  \n  ```{.r .cell-code}\n  # parameters\n  parameters::parameters(model, standardize = \"refit\")\n  ```\n  \n  ::: {.cell-output .cell-output-stdout}\n  \n  ```\n  Parameter       | Coefficient |   SE |        95% CI |   t(287) |      p\n  ------------------------------------------------------------------------\n  (Intercept)     |    2.10e-16 | 0.06 | [-0.11, 0.11] | 3.70e-15 | > .999\n  approach effort |        0.28 | 0.06 | [ 0.17, 0.39] |     4.88 | < .001\n  ```\n  \n  \n  :::\n  :::\n\n  \n- Performance metrics\n\n\n  ::: {.cell}\n  \n  ```{.r .cell-code}\n  # performance\n  performance::performance(model)\n  ```\n  \n  ::: {.cell-output .cell-output-stdout}\n  \n  ```\n  # Indices of model performance\n  \n  AIC      |     AICc |      BIC |    R2 | R2 (adj.) |    RMSE |   Sigma\n  ----------------------------------------------------------------------\n  4346.450 | 4346.534 | 4357.449 | 0.077 |     0.073 | 441.638 | 443.174\n  ```\n  \n  \n  :::\n  :::\n\n\n## Model assumptions\n\nWe can use the `check_model()` function to check whether the assumptions of a linear regression are met.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nperformance::check_model(model)\n```\n\n::: {.cell-output-display}\n![](startr-08_statistics_files/figure-revealjs/unnamed-chunk-12-1.png){width=960}\n:::\n:::\n\n\n## Multiple regression\n\nWe can also use the `lm()` function to estimate a multiple regression model. Add additional predictors with the `+` operator.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# estimate regression model with a single predictor: dv ~ iv\nmodel2 <- lm(ipaq_mvpa ~ approach_effort +\n               age + gender + intention + attitudes_instru + self_efficacy, data = pes)\nsummary(model2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = ipaq_mvpa ~ approach_effort + age + gender + intention + \n    attitudes_instru + self_efficacy, data = pes)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-589.3 -228.8  -85.6   59.4 2773.2 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(>|t|)    \n(Intercept)      -375.849    200.309  -1.876 0.061660 .  \napproach_effort    78.790     35.400   2.226 0.026842 *  \nage                 6.954      6.917   1.005 0.315570    \ngenderMale        106.515     56.090   1.899 0.058603 .  \nintention          66.808     19.735   3.385 0.000814 ***\nattitudes_instru  -13.629     23.127  -0.589 0.556146    \nself_efficacy       8.002     39.649   0.202 0.840212    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 404.4 on 277 degrees of freedom\n  (5 observations deleted due to missingness)\nMultiple R-squared:  0.1396,\tAdjusted R-squared:  0.1209 \nF-statistic: 7.489 on 6 and 277 DF,  p-value: 1.892e-07\n```\n\n\n:::\n:::\n\n\nAdd interactions with the `:` operator (e.g., `Overall:Value`). Include all main effects and interactions with the `*` operator (e.g., `Overall*Value`).\n\n## Comparing models\n\nWe can use the `compare_performance()` function to compare the performance of two or more models.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nperformance::compare_performance(model, model2, metrics = \"common\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Comparison of Model Performance Indices\n\nName   | Model |  AIC (weights) |  BIC (weights) |    R2 | R2 (adj.) |    RMSE\n------------------------------------------------------------------------------\nmodel  |    lm | 4346.4 (<.001) | 4357.4 (<.001) | 0.077 |     0.073 | 441.638\nmodel2 |    lm | 4224.3 (>.999) | 4253.5 (>.999) | 0.140 |     0.121 | 399.403\n```\n\n\n:::\n:::\n\n\n\n\n# Multivariate analyis\n\n## The *lavaan* package\n\n::: columns\n::: {.column width=\"60%\"}\n*lavaan* (**LA**tent **VA**riable **AN**alysis) is dedicated to strcutrual equation modeling (SEM)\n\n::: {.cell}\n\n```{.r .cell-code}\n# install.packages(\"lavaan\")\nlibrary(lavaan)\n```\n:::\n\n:::\n::: {.column width=\"20%\"}\n![Yves Rosseel, author of *lavaan*](figures/08-analysis/rosseel.jpg)\n:::\n:::\n\n::: footer\n<https://lavaan.ugent.be/>\n:::\n\n\n## Exploratory factor analysis (EFA)\n\nEFA can be conducted with the `efa()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# select variables of the PES\ndata <- select(pes, effort_1:effort_8)\n\n# estimate the EFA model\nfit_efa <- lavaan::efa(data = data, nfactors = 1:3)\n\n# get detailed summary of the model and request standardized loadings\nsummary(fit_efa, standardized = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nThis is lavaan 0.6.16 -- running exploratory factor analysis\n\n  Estimator                                         ML\n  Rotation method                       GEOMIN OBLIQUE\n  Geomin epsilon                                 0.001\n  Rotation algorithm (rstarts)                GPA (30)\n  Standardized metric                             TRUE\n  Row weights                                     None\n\n  Number of observations                           289\n\nOverview models:\n                    aic      bic    sabic   chisq df pvalue   cfi rmsea\n  nfactors = 1 5075.525 5134.188 5083.449 182.441 20  0.000 0.913 0.168\n  nfactors = 2 4975.991 5060.319 4987.382  68.907 13  0.000 0.970 0.122\n  nfactors = 3 4938.208 5044.534 4952.571  19.124  7  0.008 0.994 0.077\n\nEigenvalues correlation matrix:\n\n    ev1     ev2     ev3     ev4     ev5     ev6     ev7     ev8 \n  5.641   0.663   0.406   0.390   0.273   0.245   0.214   0.168 \n\nNumber of factors:  1 \n\nStandardized loadings: (* = significant at 1% level)\n\n             f1       unique.var   communalities\neffort_1  0.813*           0.339           0.661\neffort_2 -0.796*           0.366           0.634\neffort_3  0.764*           0.416           0.584\neffort_4 -0.817*           0.333           0.667\neffort_5 -0.823*           0.322           0.678\neffort_6  0.816*           0.334           0.666\neffort_7 -0.856*           0.267           0.733\neffort_8  0.826*           0.318           0.682\n\n                           f1\nSum of squared loadings 5.306\nProportion of total     1.000\nProportion var          0.663\nCumulative var          0.663\n\nNumber of factors:  2 \n\nStandardized loadings: (* = significant at 1% level)\n\n             f1      f2       unique.var   communalities\neffort_1          0.855*           0.264           0.736\neffort_2  0.820*                   0.303           0.697\neffort_3          0.736*           0.379           0.621\neffort_4  0.954*                   0.222           0.778\neffort_5  0.677*      .            0.311           0.689\neffort_6          0.908*           0.243           0.757\neffort_7  0.714*      .            0.245           0.755\neffort_8      .   0.735*           0.282           0.718\n\n                              f2    f1 total\nSum of sq (obliq) loadings 2.943 2.809 5.752\nProportion of total        0.512 0.488 1.000\nProportion var             0.368 0.351 0.719\nCumulative var             0.368 0.719 0.719\n\nFactor correlations: (* = significant at 1% level)\n\n       f1      f2 \nf1  1.000         \nf2 -0.834*  1.000 \n\nNumber of factors:  3 \n\nStandardized loadings: (* = significant at 1% level)\n\n             f1      f2      f3       unique.var   communalities\neffort_1      .   0.896*                   0.211           0.789\neffort_2  0.323*          0.864*           0.210           0.790\neffort_3          0.727*                   0.375           0.625\neffort_4      .           0.884*           0.250           0.750\neffort_5              .   0.690*           0.315           0.685\neffort_6      .   0.857*                   0.228           0.772\neffort_7      .           0.900*           0.050           0.950\neffort_8          0.717*      .            0.292           0.708\n\n                              f3    f2    f1 total\nSum of sq (obliq) loadings 3.030 2.815 0.223 6.069\nProportion of total        0.499 0.464 0.037 1.000\nProportion var             0.379 0.352 0.028 0.759\nCumulative var             0.379 0.731 0.759 0.759\n\nFactor correlations: (* = significant at 1% level)\n\n       f1      f2      f3 \nf1  1.000                 \nf2  0.050   1.000         \nf3 -0.128  -0.822*  1.000 \n```\n\n\n:::\n:::\n\n\n\n## Confirmatory factor analysis (CFA)\n\nCFA can be conducted with the `cfa()` function.\n  \n\n::: {.cell}\n\n```{.r .cell-code}\n# define the model as character string\nmodel <- \"\n  approach  =~ effort_1 + effort_3 + effort_6 + effort_8 # `=~` defines latent variables\n  avoidance =~ effort_2 + effort_4 + effort_5 + effort_7\n\n  approach ~~ avoidance  # `=~` defines relationships between latent variables\n\"\n\n# estimate the CFA model and request orthogonal rotation\nfit_cfa <- lavaan::cfa(model, data = pes)\n\n# get detailed summary of the model\nsummary(fit_cfa, fit.measures = TRUE, standardized = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nlavaan 0.6.16 ended normally after 30 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        17\n\n  Number of observations                           289\n\nModel Test User Model:\n                                                      \n  Test statistic                                76.292\n  Degrees of freedom                                19\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                              1894.480\n  Degrees of freedom                                28\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.969\n  Tucker-Lewis Index (TLI)                       0.955\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -2468.688\n  Loglikelihood unrestricted model (H1)      -2430.542\n                                                      \n  Akaike (AIC)                                4971.376\n  Bayesian (BIC)                              5033.705\n  Sample-size adjusted Bayesian (SABIC)       4979.796\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.102\n  90 Percent confidence interval - lower         0.079\n  90 Percent confidence interval - upper         0.127\n  P-value H_0: RMSEA <= 0.050                    0.000\n  P-value H_0: RMSEA >= 0.080                    0.941\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.026\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  approach =~                                                           \n    effort_1          1.000                               0.868    0.859\n    effort_3          0.942    0.058   16.375    0.000    0.817    0.790\n    effort_6          0.952    0.051   18.752    0.000    0.826    0.858\n    effort_8          0.924    0.050   18.617    0.000    0.802    0.854\n  avoidance =~                                                          \n    effort_2          1.000                               0.922    0.822\n    effort_4          1.041    0.060   17.401    0.000    0.960    0.853\n    effort_5          1.014    0.059   17.140    0.000    0.935    0.845\n    effort_7          1.018    0.056   18.338    0.000    0.939    0.884\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  approach ~~                                                           \n    avoidance        -0.697    0.075   -9.342    0.000   -0.871   -0.871\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .effort_1          0.268    0.029    9.177    0.000    0.268    0.263\n   .effort_3          0.401    0.039   10.354    0.000    0.401    0.375\n   .effort_6          0.244    0.027    9.192    0.000    0.244    0.264\n   .effort_8          0.238    0.026    9.283    0.000    0.238    0.270\n   .effort_2          0.408    0.041   10.052    0.000    0.408    0.324\n   .effort_4          0.344    0.036    9.475    0.000    0.344    0.272\n   .effort_5          0.351    0.036    9.657    0.000    0.351    0.286\n   .effort_7          0.247    0.029    8.622    0.000    0.247    0.219\n    approach          0.753    0.084    8.952    0.000    1.000    1.000\n    avoidance         0.851    0.101    8.381    0.000    1.000    1.000\n```\n\n\n:::\n:::\n\n\n## Structural equation modeling (SEM)\n\nSEM can be conducted with the `sem()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# define the model as character string\nmodel <- \"\n  approach  =~ effort_1 + effort_3 + effort_6 + effort_8\n  avoidance =~ effort_2 + effort_4 + effort_5 + effort_7\n\n  approach ~~ avoidance\n  approach  ~ intention + automaticity + self_efficacy + motivation_auto + attitudes_affect\n  avoidance ~ intention + automaticity + self_efficacy + motivation_auto + attitudes_affect\n\"\n\n# estimate the CFA model and request orthogonal rotation\nfit_sem <- lavaan::sem(model, data = pes)\n\n# get detailed summary of the model\nsummary(fit_sem, fit.measures = TRUE, standardized = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nlavaan 0.6.16 ended normally after 35 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        27\n\n                                                  Used       Total\n  Number of observations                           285         289\n\nModel Test User Model:\n                                                      \n  Test statistic                               129.692\n  Degrees of freedom                                49\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                              2224.158\n  Degrees of freedom                                68\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.963\n  Tucker-Lewis Index (TLI)                       0.948\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)              -2286.297\n  Loglikelihood unrestricted model (H1)      -2221.451\n                                                      \n  Akaike (AIC)                                4626.594\n  Bayesian (BIC)                              4725.212\n  Sample-size adjusted Bayesian (SABIC)       4639.593\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.076\n  90 Percent confidence interval - lower         0.060\n  90 Percent confidence interval - upper         0.092\n  P-value H_0: RMSEA <= 0.050                    0.004\n  P-value H_0: RMSEA >= 0.080                    0.356\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.027\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  approach =~                                                           \n    effort_1          1.000                               0.885    0.875\n    effort_3          0.929    0.054   17.050    0.000    0.822    0.793\n    effort_6          0.913    0.048   18.906    0.000    0.808    0.840\n    effort_8          0.894    0.046   19.260    0.000    0.791    0.848\n  avoidance =~                                                          \n    effort_2          1.000                               0.927    0.826\n    effort_4          1.052    0.059   17.693    0.000    0.975    0.862\n    effort_5          1.008    0.059   17.061    0.000    0.934    0.842\n    effort_7          1.007    0.055   18.183    0.000    0.934    0.878\n\nRegressions:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n  approach ~                                                            \n    intention         0.033    0.028    1.149    0.251    0.037    0.054\n    automaticity      0.125    0.030    4.205    0.000    0.142    0.216\n    self_efficacy     0.128    0.054    2.394    0.017    0.145    0.109\n    motivation_aut    0.470    0.062    7.630    0.000    0.531    0.505\n    attitudes_ffct    0.069    0.035    1.969    0.049    0.078    0.102\n  avoidance ~                                                           \n    intention        -0.083    0.037   -2.271    0.023   -0.090   -0.132\n    automaticity     -0.044    0.038   -1.144    0.253   -0.047   -0.072\n    self_efficacy    -0.071    0.069   -1.025    0.305   -0.076   -0.057\n    motivation_aut   -0.481    0.080   -6.023    0.000   -0.518   -0.492\n    attitudes_ffct   -0.041    0.045   -0.899    0.369   -0.044   -0.057\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n .approach ~~                                                           \n   .avoidance        -0.232    0.029   -7.918    0.000   -0.741   -0.741\n\nVariances:\n                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n   .effort_1          0.240    0.026    9.277    0.000    0.240    0.234\n   .effort_3          0.399    0.038   10.589    0.000    0.399    0.371\n   .effort_6          0.273    0.027   10.009    0.000    0.273    0.294\n   .effort_8          0.244    0.025    9.867    0.000    0.244    0.280\n   .effort_2          0.400    0.040    9.947    0.000    0.400    0.318\n   .effort_4          0.329    0.036    9.240    0.000    0.329    0.257\n   .effort_5          0.359    0.037    9.679    0.000    0.359    0.292\n   .effort_7          0.260    0.030    8.808    0.000    0.260    0.230\n   .approach          0.228    0.029    7.830    0.000    0.291    0.291\n   .avoidance         0.431    0.054    7.974    0.000    0.502    0.502\n```\n\n\n:::\n:::\n\n\n## Plotting the model\n\nWe can use the `semPaths()` function in the `semPlot` package to plot the estimated models. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# install.packages(\"semPlot\")\nlibrary(semPlot)\nsemPaths(fit_sem, what = \"std\")\n```\n\n::: {.cell-output-display}\n![](startr-08_statistics_files/figure-revealjs/unnamed-chunk-19-1.png){width=960}\n:::\n:::\n\n\n\n## {{< iconify solar programming-bold >}} Exercise\n\n::: {.incremental}\n1.  Open your `pes` project (see work flow) and import the data from the file `pes.csv`.\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code  code-fold=\"true\" code-summary=\"Solution\" code-line-numbers=\"false\"}\n    library(rio)\n    pes <- import(\"data/pes.csv\")\n    ```\n    :::\n\n\n2.  Compute the correlation of `approach_effort` and `avoid_effort` with `ipaq_mvpa`.\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code  code-fold=\"true\" code-summary=\"Solution\" code-line-numbers=\"false\"}\n    correlation(pes, data = select(pes, approach_effort, avoid_effort),\n                     data2 = select(pes, ipaq_mvpa))\n    ```\n    :::\n\n\n3.  Regress `ipaq_mvpa` on `approach_effort` and `avoid_effort`. Investigate the standardized parameters and the model performance.\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code  code-fold=\"true\" code-summary=\"Solution\" code-line-numbers=\"false\"}\n    reg_model <- lm(ipaq_mvpa ~ approach_effort + avoid_effort, data = pes)\n    parameters::parameters(reg_model, standardize = \"refit\")\n    performance::performance(reg_model)\n    ```\n    :::\n\n\n4.  Estimate a SEM model with `approach_effort` and `avoid_effort` as latent variables and predictors of the manifest variable `ipaq_mvpa`. \n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code  code-fold=\"true\" code-summary=\"Solution\" code-line-numbers=\"false\"}\n    model <- \"approach  =~ effort_1 + effort_3 + effort_6 + effort_8\n              avoidance =~ effort_2 + effort_4 + effort_5 + effort_7\n    \n              approach ~~ avoidance\n              ipaq_mvpa_std ~ approach + avoidance\"\n    \n    fit_sem <- lavaan::sem(model, data = pes)\n    summary(fit_sem, fit.measures = TRUE, standardized = TRUE)\n    ```\n    :::\n\n\n:::\n\n\n\n\n\n\n\n\n# t-Tests\n\n## Single sample *t*-test\n\n*t*-tests can be performed with the `t.test()` function in base R. If one variable is provided, a single sample *t*-test is performed. Similar to regression, the model paramters can be examined with the `parameters()` function of the *parameters* package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# test whether pre-training performance is different from 0\nmodel <- t.test(hiit$RSA_Pre)\n\n# get the standard output\nmodel\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tOne Sample t-test\n\ndata:  hiit$RSA_Pre\nt = 44.879, df = 21, p-value < 2.2e-16\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 4.786515 5.251667\nsample estimates:\nmean of x \n 5.019091 \n```\n\n\n:::\n\n```{.r .cell-code}\n# get tidy output with parameters()\nparameters::parameters(model, es_type = \"cohens_d\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOne Sample t-test\n\nParameter    |   mu | Difference |       95% CI | Cohen's d |      d 95% CI | t(21) |      p\n--------------------------------------------------------------------------------------------\nhiit$RSA_Pre | 0.00 |       5.02 | [4.79, 5.25] |      9.57 | [6.66, 12.38] | 44.88 | < .001\n\nAlternative hypothesis: true mean is not equal to 0\n```\n\n\n:::\n:::\n\n\n## Independent *t*-test\n\nAn independent *t*-Test using the formula approach.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compare pre-training performance between males and females\nmodel <- t.test(RSA_Pre ~ Sex, data = hiit)\n\n# get tidy output with parameters()\nparameters::parameters(model, es_type = \"cohens_d\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nWelch Two Sample t-test\n\nParameter | Group | Mean_Group1 | Mean_Group2 | Difference |         95% CI |     d |       d 95% CI | t(17.15) |      p\n------------------------------------------------------------------------------------------------------------------------\nRSA_Pre   |   Sex |        4.56 |        5.48 |      -0.91 | [-1.13, -0.70] | -4.27 | [-5.95, -2.54] |    -8.84 | < .001\n\nAlternative hypothesis: true difference in means between group female and group male is not equal to 0\n```\n\n\n:::\n:::\n\n\n## Dependent *t*-test\n\nA dependent *t*-Test specifying both variables and using the `paired` argument.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compare pre- and post-training performance within individuals\nmodel <- t.test(hiit$RSA_Pre, hiit$RSA_Post1, paired = TRUE)\n\n# get tidy output with parameters()\nparameters::parameters(model, es_type = \"cohens_d\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPaired t-test\n\nParameter    |          Group | Difference |       95% CI | Cohen's d |     d 95% CI | t(21) |      p\n-----------------------------------------------------------------------------------------------------\nhiit$RSA_Pre | hiit$RSA_Post1 |       0.18 | [0.13, 0.23] |      1.48 | [0.86, 2.08] |  6.92 | < .001\n\nAlternative hypothesis: true mean difference is not equal to 0\n```\n\n\n:::\n:::\n\n\n\n\n\n\n# ANOVA\n\n## The *afex* and the *emmeans* package\n\n::: columns\n::: {.column width=\"60%\"}\n*afex* (**A**nalysis of **F**actorial **EX**periments) is dedicated to analysis of variance.\n\n::: {.cell}\n\n```{.r .cell-code}\n# install.packages(\"afex\")\nlibrary(afex)\n```\n:::\n\n:::\n::: {.column width=\"20%\"}\n![Henrik Singman, author of *afex*](figures/08-analysis/singmann.jpg)\n:::\n:::\n\n::: columns\n::: {.column width=\"60%\"}\n*emmeans* (**E**stimated **M**arginal **MEANS**) is dedicated to follow-up contrasts and post-hoc tests.\n\n::: {.cell}\n\n```{.r .cell-code}\n# install.packages(\"emmeans\")\nlibrary(emmeans)\n```\n:::\n\n:::\n::: {.column width=\"20%\"}\n![Russell Lenth, author of *emmeans*](figures/08-analysis/lenth.jpg)\n:::\n:::\n\n::: footer\n<https://github.com/singmann/afex> - <https://github.com/rvlenth/emmeans>\n:::\n\n\n\n## The `aov_4()` function\n\nThe `aov_4()` function is part of the `afex` package and can be used to estimate a variety of ANOVA models. \n\n::: callout-important\n## Generic format: `aov_4(dv ~ iv_b + (iv_w | id), data)`\n:::\n\n- `dv` is the dependent variable\n- `iv_b` are the between-subject predictor variables\n- `iv_w` are the within-subject predictor variables\n- `id` is the subject identifier variable\n- `data` is the data frame\n\n\n## The `emmeans()` function\n\nThe `emmeans()` function is part of the `emmeans` package. It has the following generic format:\n\n::: callout-important\n## Generic format: `emmeans(model, ~ iv)`\n:::\n\n- `model` is the model object\n- `iv` are the predictor variables\n\n\n\n## Reshaping the HIIT dataset\n\nFor the ANOVA, we need a long version of the HIIT dataset. We can use the `pivot_longer()` function from the `tidyr` package to convert the dataset from wide to long format (see \"data management\").\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# wide format\nhead(hiit[, 1:10])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   ID  Sex RSA_Pre RSA_Post1 RSA_Post2 CMJ_Pre CMJ_Post1 CMJ_Post2 MRJ_Pre\n1  P4 male    5.79      5.74      5.81    42.5      40.7      39.7    2.13\n2  P7 male    5.10      4.87      5.09    40.7      33.3      35.1    1.98\n3  P8 male    5.71      5.45      5.57    38.5      34.6      34.8    1.42\n4  P9 male    5.61      5.38      5.43    48.3      44.3      46.8    2.07\n5 P10 male    5.51      5.38      5.49    39.8      37.1      37.4    1.88\n6 P11 male    5.25      5.12      5.16    33.9      31.3      33.6    1.62\n  MRJ_Post1\n1      1.97\n2      1.46\n3      1.08\n4      1.80\n5      1.37\n6      1.59\n```\n\n\n:::\n\n```{.r .cell-code}\n# convert to long format\nhiit_long <- tidyr::pivot_longer(hiit, cols = -c(ID, Sex), names_sep = \"_\",\n                                 names_to = c(\"Measurement\", \"Time\"), values_to = \"Value\")\n\n# wide format\nhead(hiit_long)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 Ã— 5\n  ID    Sex   Measurement Time  Value\n  <chr> <chr> <chr>       <chr> <dbl>\n1 P4    male  RSA         Pre    5.79\n2 P4    male  RSA         Post1  5.74\n3 P4    male  RSA         Post2  5.81\n4 P4    male  CMJ         Pre   42.5 \n5 P4    male  CMJ         Post1 40.7 \n6 P4    male  CMJ         Post2 39.7 \n```\n\n\n:::\n:::\n\n\n\n\n## One-factorial ANOVA\n\n**Between-subject ANOVA**\n\n::: {.cell}\n\n```{.r .cell-code}\n# Select data for the RSA measurement at the pre-training time point\ndata <- dplyr::filter(hiit_long, Measurement == \"RSA\" & Time == \"Pre\")\n\n# Test whether the pre RSA values differ between females and males\nafex::aov_4(Value ~ Sex + (1 | ID), data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnova Table (Type 3 tests)\n\nResponse: Value\n  Effect    df  MSE         F  ges p.value\n1    Sex 1, 20 0.06 78.09 *** .796   <.001\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n. . .\n\n**Within-subject ANOVA**\n\n::: {.cell}\n\n```{.r .cell-code}\n# Select data for the RSA measurement (all time points)\ndata <- dplyr::filter(hiit_long, Measurement == \"RSA\")\n\n# Test whether the RSA values differ between the time points\nafex::aov_4(Value ~ 1 + (Time | ID), data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnova Table (Type 3 tests)\n\nResponse: Value\n  Effect          df  MSE       F  ges p.value\n1   Time 1.30, 27.20 0.04 7.16 ** .020    .008\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n\nSphericity correction method: GG \n```\n\n\n:::\n:::\n\n\nNote that a sphericity correction is applied by default.\n\n\n## Pairwise comparisons\n\nWe can use the `emmeans()` function to estimate marginal means and the `pairs()` function to conduct pairwise comparisons. Per default, the Tukey adjustment is used.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Select data for the RSA measurement (all time points)\ndata  <- dplyr::filter(hiit_long, Measurement == \"RSA\")\n\n# Estimate the ANOVA model with Time as within-subject predictor\nmodel <- afex::aov_4(Value ~ 1 + (Time | ID), data)\n\n# Esimate the marginal means\nemm <- emmeans::emmeans(model, ~ Time)\nemm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Time  emmean    SE df lower.CL upper.CL\n Pre     5.02 0.112 21     4.79     5.25\n Post1   4.84 0.118 21     4.59     5.09\n Post2   4.97 0.119 21     4.73     5.22\n\nConfidence level used: 0.95 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Conduct pairwise comparisons\npairs(emm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n contrast      estimate     SE df t.ratio p.value\n Pre - Post1     0.1795 0.0259 21   6.921  <.0001\n Pre - Post2     0.0459 0.0601 21   0.764  0.7289\n Post1 - Post2  -0.1336 0.0548 21  -2.440  0.0589\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n```\n\n\n:::\n:::\n\n\n\n\n## Mixed ANOVA\n\nFor a mixed ANOVA, we can include both between- and within-subject predictors in the `aox_4()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Select data for the RSA measurement (all time points)\ndata <- dplyr::filter(hiit_long, Measurement == \"RSA\")\n\n# Estimate the ANOVA model with Sex as between-subject and Time as within-subject predictor\nafex::aov_4(Value ~ Sex + (Time | ID), data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnova Table (Type 3 tests)\n\nResponse: Value\n    Effect          df  MSE         F  ges p.value\n1      Sex       1, 20 0.16 90.01 *** .770   <.001\n2     Time 1.26, 25.24 0.04   6.97 ** .081    .010\n3 Sex:Time 1.26, 25.24 0.04      0.43 .005    .566\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n\nSphericity correction method: GG \n```\n\n\n:::\n:::\n\n\n\n\n## Simple effects\n\nTo follow up on significant interactions, we can estimate simple main effects using the `joint_tests()` function. Here, we test the simple effects of `Sex` at each level of `Time`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Select data for the RSA measurement (all time points)\ndata <- dplyr::filter(hiit_long, Measurement == \"RSA\")\n\n# Estimate the ANOVA model with Sex as between-subject and Time as within-subject predictor\nmodel <- afex::aov_4(Value ~ Sex + (Time | ID), data)\n\n# Esimate the marginal means\nemm <- emmeans::emmeans(model, ~ Sex * Time)\n\n# Estimate simple effects\nemmeans::joint_tests(emm, by = \"Time\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTime = Pre:\n model term df1 df2 F.ratio p.value\n Sex          1  20  78.087  <.0001\n\nTime = Post1:\n model term df1 df2 F.ratio p.value\n Sex          1  20  99.553  <.0001\n\nTime = Post2:\n model term df1 df2 F.ratio p.value\n Sex          1  20  43.946  <.0001\n```\n\n\n:::\n:::\n\n\n\n## {{< iconify solar programming-bold >}} Exercise\n\n::: {.incremental}\n1.  Open your `hiit` project (see work flow) and import the data from the file `hiit.csv`.\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code  code-fold=\"true\" code-summary=\"Solution\" code-line-numbers=\"false\"}\n    library(rio)\n    hiit <- import(\"data/hiit.csv\")\n    ```\n    :::\n\n\n2.  Run a t-test to examine gender differences in `CMJ` performance at time point `pre`.\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code  code-fold=\"true\" code-summary=\"Solution\" code-line-numbers=\"false\"}\n    model <- t.test(hiit$CMJ_Pre ~ hiit$Sex)\n    parameters::parameters(model)\n    ```\n    :::\n\n\n3.  Run an ANOVA to examine gender differences in `CMJ` performance at all three time points. Use the following code to reshape the data for the analysis.\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    hiit_long <- tidyr::pivot_longer(hiit, cols = -c(ID, Sex), names_sep = \"_\",\n                                 names_to = c(\"Measurement\", \"Time\"), values_to = \"Value\")\n    ```\n    :::\n\n    ::: {.cell}\n    \n    ```{.r .cell-code  code-fold=\"true\" code-summary=\"Solution\" code-line-numbers=\"false\"}\n    data <- dplyr::filter(hiit_long, Measurement == \"CMJ\")\n    model <- afex::aov_4(Value ~ Sex + (1 + Time | ID), data)\n    model\n    ```\n    :::\n\n\n4.  Determine the simple effects of gender at each time point.\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code  code-fold=\"true\" code-summary=\"Solution\" code-line-numbers=\"false\"}\n    # Esimate the marginal means\n    emm <- emmeans::emmeans(model, ~ Sex * Time)\n    \n    # Estimate simple effects\n    emmeans::joint_tests(emm, by = \"Time\")\n    ```\n    :::\n\n:::",
    "supporting": [
      "startr-08_statistics_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}