{
  "hash": "0ce98f86c769f92585f2b13540c90977",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Hypothesis Testing\"\nsubtitle: \"StartR Workshop\"\ndescription: \"Correlation | Regression | t-Tests | ANOVA\"\nauthor: \"Maik Bieleke, PhD\"\ninstitute: \"University of Konstanz\"\ndate: 11/24/2024\ndate-format: long\nformat: \n  revealjs:\n    fontsize: 24pt\n    chalkboard: false\n    embed-resources: true\n    slide-number: true\n    theme: [simple, _styles/unikn.scss]\n    logo: _styles/icon.png\n    footer: \"[www.maikbieleke.com](https://www.maikbieleke.com)\"\n    margin: 0.2\n    incremental: false \n    slide-level: 2\n    highlight-style: a11y\n    preview-links: true\nfrom: markdown+emoji\nrevealjs-plugins:\n  - attribution\n---\n\n::: {.cell}\n\n:::\n\n```{=html}\n<style> td,th {font-size: 25px} </style>\n```\n\n\n# Correlation\n\n## The *correlation* package\n\n::: columns\n::: {.column width=\"60%\"}\nThe *correlation* package is an [easystats package](https://easystats.github.io/easystats/) focused on correlation analysis.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# install.packages(\"correlation\")\nlibrary(correlation)\n```\n:::\n\n:::\n\n::: {.column width=\"40%\"}\n![](figures/correlation-hex.png){fig-align=\"center\"}\n:::\n:::\n\n::: footer\n<https://easystats.github.io/easystats/>\n:::\n\n## Computing single correlations\n\nA single correlation can be determined with the `cor_test()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Correlation between players' value and overall attribute\ncor_test(fifa, \"Overall\", \"Value\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nParameter1 | Parameter2 |    r |       95% CI | t(17658) |         p\n--------------------------------------------------------------------\nOverall    |      Value | 0.56 | [0.55, 0.57] |    90.81 | < .001***\n\nObservations: 17660\n```\n\n\n:::\n:::\n\n\n\n\n## Plotting single correlations\n\nWe can plot the correlation using the `plot()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nr <- cor_test(fifa, \"Overall\", \"Value\")\nplot(r)\n```\n\n::: {.cell-output-display}\n![](startr-09_statistics_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n\n\n\n## Computing multiple correlations\n\nWe can compute correlations between multiple variables with the `correlation()` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Select variables of interest\nvariables <- select(fifa, Overall, Potential, Value, Wage)\n\n# Compute correlations\ncorrelation(variables)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Correlation Matrix (pearson-method)\n\nParameter1 | Parameter2 |    r |       95% CI | t(17658) |         p\n--------------------------------------------------------------------\nOverall    |  Potential | 0.71 | [0.70, 0.71] |   132.69 | < .001***\nOverall    |      Value | 0.56 | [0.55, 0.57] |    90.81 | < .001***\nOverall    |       Wage | 0.60 | [0.59, 0.61] |    99.55 | < .001***\nPotential  |      Value | 0.51 | [0.50, 0.52] |    79.02 | < .001***\nPotential  |       Wage | 0.48 | [0.47, 0.49] |    72.58 | < .001***\nValue      |       Wage | 0.81 | [0.81, 0.82] |   183.96 | < .001***\n\np-value adjustment method: Holm (1979)\nObservations: 17660\n```\n\n\n:::\n:::\n\n\n\n\n## Plotting multiple correlations\n\nWe can use the `summary()`function to get a correlation matrix.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compute and save correlations\nr <- correlation(variables)\n\n# Generate correlation matrix\nsummary(r)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Correlation Matrix (pearson-method)\n\nParameter |    Wage |   Value | Potential\n-----------------------------------------\nOverall   | 0.60*** | 0.56*** |   0.71***\nPotential | 0.48*** | 0.51*** |          \nValue     | 0.81*** |         |          \n\np-value adjustment method: Holm (1979)\n```\n\n\n:::\n:::\n\n\n\n\n## Correlation plot\n\nWe can use the `plot()`function to plot the correlation matrix.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compute and save correlations and correlation matrix\nr <- correlation(variables)\nrmat <- summary(r)\n\n# Generate correlation plot\nplot(rmat)\n```\n\n::: {.cell-output-display}\n![](startr-09_statistics_files/figure-revealjs/unnamed-chunk-7-1.png){width=960}\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n# Regression\n\n## Overview\n\nThere are numerous regression models available in R. We will focus on the Base R implementation of the linear regression model.\n\n::: columns\n::: {.column width=\"70%\"}\nThere are three aspects of regression:\n\n-   **model estimation**: `lm()` function in base R\n-   **parameter evaluation**: *parameters* package\n-   **model performance**: *performance* package\n:::\n\n::: {.column width=\"30%\"}\n![](figures/parameters-hex.png) ![](figures/performance-hex.png)\n:::\n:::\n\nThe *parameters* and the *performance* package are part of the [easystats](https://easystats.github.io/easystats/) package collection.\n\n::: footer\n<https://easystats.github.io/easystats/>\n:::\n\n## Simple regression\n\nWe can use the `lm()` function to estimate a simple linear regression model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# estimate regression model with a single predictor: dv ~ iv\nmodel <- lm(Wage ~ Overall, data = fifa)\n\n# get the standard output\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Wage ~ Overall, data = fifa)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-39708  -7903  -2542   5097 399598 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -88622.18     980.27  -90.41   <2e-16 ***\nOverall       1527.74      15.35   99.55   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 16390 on 17658 degrees of freedom\nMultiple R-squared:  0.3595,\tAdjusted R-squared:  0.3595 \nF-statistic:  9911 on 1 and 17658 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n## Model parameters and performance\n\nWe can use the `parameters()` and `performance()` to evaluate the model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# parameters\nparameters::parameters(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nParameter   | Coefficient |     SE |                 95% CI | t(17658) |      p\n-------------------------------------------------------------------------------\n(Intercept) |   -88622.18 | 980.27 | [-90543.60, -86700.76] |   -90.41 | < .001\nOverall     |     1527.74 |  15.35 | [  1497.66,   1557.82] |    99.55 | < .001\n```\n\n\n:::\n\n```{.r .cell-code}\n# performance\nperformance::performance(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Indices of model performance\n\nAIC       |      AICc |       BIC |    R2 | R2 (adj.) |      RMSE |     Sigma\n-----------------------------------------------------------------------------\n3.929e+05 | 3.929e+05 | 3.929e+05 | 0.359 |     0.359 | 16387.478 | 16388.406\n```\n\n\n:::\n:::\n\n\n## Model assumptions\n\nWe can use the `check_model()` function to check whether the assumptions of a linear regression are met.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nperformance::check_model(model)\n```\n\n::: {.cell-output-display}\n![](startr-09_statistics_files/figure-revealjs/unnamed-chunk-10-1.png){width=960}\n:::\n:::\n\n\n## Multiple regression\n\nWe can also use the `lm()` function to estimate a multiple regression model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# estimate regression model with a single predictor: dv ~ iv\nmodel2 <- lm(Wage ~ Overall + Value, data = fifa)\nsummary(model2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Wage ~ Overall + Value, data = fifa)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-132632   -3555    -908    2282  316273 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -3.045e+04  8.083e+02  -37.67   <2e-16 ***\nOverall      5.315e+02  1.300e+01   40.89   <2e-16 ***\nValue        1.810e-03  1.332e-05  135.83   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11460 on 17657 degrees of freedom\nMultiple R-squared:  0.6868,\tAdjusted R-squared:  0.6867 \nF-statistic: 1.936e+04 on 2 and 17657 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n## Comparing models\n\nWe can use the `compare_performance()` function to compare the performance of two or more models.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nperformance::compare_performance(model, model2, metrics = \"common\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Comparison of Model Performance Indices\n\nName   | Model |   AIC (weights) |   BIC (weights) |    R2 | R2 (adj.) |      RMSE\n----------------------------------------------------------------------------------\nmodel  |    lm | 3.9e+05 (<.001) | 3.9e+05 (<.001) | 0.359 |     0.359 | 16387.478\nmodel2 |    lm | 3.8e+05 (>.999) | 3.8e+05 (>.999) | 0.687 |     0.687 | 11459.711\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n# t-Tests\n\n## The `t-test()` function\n\nThe `t-test()` function has two basic forms:\n\n| Test          | Wide Format                | Long Format                       |\n|---------------|----------------------------|-----------------------------------|\n| One-sample | `t.test(x)`                |                                   |\n| Independent   | `t.test(x, y)`             | `t.test(y ~ x, data)`             |\n| Dependent     | `t.test(x, y, paired = T)` | `t.test(y ~ x, data, paired = T)` |\n\n: {tbl-colwidths=\"\\[10, 40, 50\\]\"}\n\nThe function has various additional options, e.g.\n\n- `var.equal` for equal variances (`TRUE` or `FALSE`)  \n- `alternative` for one-sided tests (`less` or `more`)\n- `mu` for the null hypothesis value (default is 0)\n- `conf.level` for the confidence interval (default is 0.95)\n\n## Single sample t-test\n\nt-tests can be performed with the `t.test()` function in base R. If one variable is provided, a single sample t-test is performed.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Test whether pre-training performance is different from 0\nt.test(hiit$RSA_Pre)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tOne Sample t-test\n\ndata:  hiit$RSA_Pre\nt = 44.879, df = 21, p-value < 2.2e-16\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 4.786515 5.251667\nsample estimates:\nmean of x \n 5.019091 \n```\n\n\n:::\n:::\n\n\n## Independent t-test\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compare pre-training performance between males and females\nt.test(RSA_Pre ~ Sex, data = hiit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  RSA_Pre by Sex\nt = -8.8367, df = 17.154, p-value = 8.54e-08\nalternative hypothesis: true difference in means between group female and group male is not equal to 0\n95 percent confidence interval:\n -1.1327500 -0.6963409\nsample estimates:\nmean in group female   mean in group male \n            4.561818             5.476364 \n```\n\n\n:::\n:::\n\n\n## Dependent t-test\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Compare pre- and post-training performance within individuals\nt.test(hiit$RSA_Pre, hiit$RSA_Post1, paired = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tPaired t-test\n\ndata:  hiit$RSA_Pre and hiit$RSA_Post1\nt = 6.9213, df = 21, p-value = 7.733e-07\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.1255983 0.2334927\nsample estimates:\nmean difference \n      0.1795455 \n```\n\n\n:::\n:::\n\n\n\n\n\n\n# ANOVA\n\n## The *afex* and the *emmeans* package\n\n::: columns\n::: {.column width=\"60%\"}\n*afex* (**A**nalysis of **F**actorial **EX**periments) is dedicated to analysis of variance.\n\n::: {.cell}\n\n```{.r .cell-code}\n# install.packages(\"afex\")\nlibrary(afex)\n```\n:::\n\n:::\n::: {.column width=\"20%\"}\n![Henrik Singman, author of *afex*](figures/singmann.jpg)\n:::\n:::\n\n::: columns\n::: {.column width=\"60%\"}\n*emmeans* (**E**stimated **M**arginal **MEANS**) is dedicated to post-hoc tests.\n\n::: {.cell}\n\n```{.r .cell-code}\n# install.packages(\"emmeans\")\nlibrary(emmeans)\n```\n:::\n\n:::\n::: {.column width=\"20%\"}\n![Russell Lenth, author of *emmeans*](figures/lenth.jpg)\n:::\n:::\n\n::: footer\n<https://github.com/singmann/afex> - <https://github.com/rvlenth/emmeans>\n:::\n\n\n\n## The `aov_4()` function\n\nThe `aov_4()` function is part of the `afex` package and can be used to estimate a variety of ANOVA models. \n\n::: callout-important\n## Generic format: `aov_4(dv ~ iv_b + (iv_w | id), data)`\n:::\n\n- `dv` is the dependent variable\n- `iv_b` are the between-subject predictor variables\n- `iv_w` are the within-subject predictor variables\n- `id` is the subject identifier variable\n- `data` is the data frame\n\n\n## The `emmeans()` function\n\nThe `emmeans()` function is part of the `emmeans` package. It has the following generic format:\n\n::: callout-important\n## Generic format: `emmeans(model, ~ iv)`\n:::\n\n- `model` is the model object\n- `iv` are the predictor variables\n\n\n\n## One-factorial ANOVA\n\n**Between-subject ANOVA**\n\n::: {.cell}\n\n```{.r .cell-code}\n# Between-subject predictor: Sex\ndata <- dplyr::filter(hiit_long, Measure == \"RSA\" & Time == \"Pre\")\nafex::aov_4(Value ~ Sex + (1 | ID), data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnova Table (Type 3 tests)\n\nResponse: Value\n  Effect    df  MSE         F  ges p.value\n1    Sex 1, 20 0.06 78.09 *** .796   <.001\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n**Within-subject ANOVA**\n\n::: {.cell}\n\n```{.r .cell-code}\n# Within-subject predictor: Time\ndata <- dplyr::filter(hiit_long, Measure == \"RSA\")\nafex::aov_4(Value ~ 1 + (Time | ID), data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnova Table (Type 3 tests)\n\nResponse: Value\n  Effect          df  MSE       F  ges p.value\n1   Time 1.30, 27.20 0.04 7.16 ** .020    .008\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n\nSphericity correction method: GG \n```\n\n\n:::\n:::\n\n\n\n\n## Pairwise comparisons\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Within-subject predictor: Time\ndata <- dplyr::filter(hiit_long, Measure == \"RSA\")\nmodel <- afex::aov_4(Value ~ 1 + (Time | ID), data)\n\n# Esimate the marginal means\nemm <- emmeans::emmeans(model, ~ Time)\nemm\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Time  emmean    SE df lower.CL upper.CL\n Pre     5.02 0.112 21     4.79     5.25\n Post1   4.84 0.118 21     4.59     5.09\n Post2   4.97 0.119 21     4.73     5.22\n\nConfidence level used: 0.95 \n```\n\n\n:::\n\n```{.r .cell-code}\n# Conduct pairwise comparisons\npairs(emm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n contrast      estimate     SE df t.ratio p.value\n Pre - Post1     0.1795 0.0259 21   6.921  <.0001\n Pre - Post2     0.0459 0.0601 21   0.764  0.7289\n Post1 - Post2  -0.1336 0.0548 21  -2.440  0.0589\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n```\n\n\n:::\n:::\n\n\n\n\n## Mixed ANOVA\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Between-subject predictor: Sex, Within-subject predictor: Time\ndata <- dplyr::filter(hiit_long, Measure == \"RSA\")\nafex::aov_4(Value ~ Sex + (Time | ID), data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnova Table (Type 3 tests)\n\nResponse: Value\n    Effect          df  MSE         F  ges p.value\n1      Sex       1, 20 0.16 90.01 *** .770   <.001\n2     Time 1.26, 25.24 0.04   6.97 ** .081    .010\n3 Sex:Time 1.26, 25.24 0.04      0.43 .005    .566\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '+' 0.1 ' ' 1\n\nSphericity correction method: GG \n```\n\n\n:::\n:::\n\n\n\n\n## Simple effects\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Between-subject predictor: Sex, Within-subject predictor: Time\ndata <- dplyr::filter(hiit_long, Measure == \"RSA\")\nmodel <- afex::aov_4(Value ~ Sex + (Time | ID), data)\n\n# Esimate the marginal means\nemm <- emmeans::emmeans(model, ~ Sex * Time)\n\n# Estimate simple effects\nemmeans::joint_tests(emm, by = \"Time\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTime = Pre:\n model term df1 df2 F.ratio p.value\n Sex          1  20  78.087  <.0001\n\nTime = Post1:\n model term df1 df2 F.ratio p.value\n Sex          1  20  99.553  <.0001\n\nTime = Post2:\n model term df1 df2 F.ratio p.value\n Sex          1  20  43.946  <.0001\n```\n\n\n:::\n:::",
    "supporting": [
      "startr-09_statistics_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}